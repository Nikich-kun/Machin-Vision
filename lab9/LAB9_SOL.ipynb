{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      " - 0s - loss: 0.9244 - acc: 0.6667\n",
      "Epoch 2/150\n",
      " - 0s - loss: 0.9243 - acc: 0.6667\n",
      "Epoch 3/150\n",
      " - 0s - loss: 0.9241 - acc: 0.6667\n",
      "Epoch 4/150\n",
      " - 0s - loss: 0.9240 - acc: 0.6667\n",
      "Epoch 5/150\n",
      " - 0s - loss: 0.9237 - acc: 0.6667\n",
      "Epoch 6/150\n",
      " - 0s - loss: 0.9234 - acc: 0.7800\n",
      "Epoch 7/150\n",
      " - 0s - loss: 0.9224 - acc: 1.0000\n",
      "Epoch 8/150\n",
      " - 0s - loss: 0.9216 - acc: 0.8733\n",
      "Epoch 9/150\n",
      " - 0s - loss: 0.9201 - acc: 1.0000\n",
      "Epoch 10/150\n",
      " - 0s - loss: 0.9177 - acc: 1.0000\n",
      "Epoch 11/150\n",
      " - 0s - loss: 0.9141 - acc: 1.0000\n",
      "Epoch 12/150\n",
      " - 0s - loss: 0.9092 - acc: 1.0000\n",
      "Epoch 13/150\n",
      " - 0s - loss: 0.9019 - acc: 1.0000\n",
      "Epoch 14/150\n",
      " - 0s - loss: 0.8918 - acc: 1.0000\n",
      "Epoch 15/150\n",
      " - 0s - loss: 0.8795 - acc: 1.0000\n",
      "Epoch 16/150\n",
      " - 0s - loss: 0.8661 - acc: 1.0000\n",
      "Epoch 17/150\n",
      " - 0s - loss: 0.8508 - acc: 1.0000\n",
      "Epoch 18/150\n",
      " - 0s - loss: 0.8350 - acc: 1.0000\n",
      "Epoch 19/150\n",
      " - 0s - loss: 0.8194 - acc: 1.0000\n",
      "Epoch 20/150\n",
      " - 0s - loss: 0.8055 - acc: 1.0000\n",
      "Epoch 21/150\n",
      " - 0s - loss: 0.7915 - acc: 1.0000\n",
      "Epoch 22/150\n",
      " - 0s - loss: 0.7796 - acc: 1.0000\n",
      "Epoch 23/150\n",
      " - 0s - loss: 0.7689 - acc: 1.0000\n",
      "Epoch 24/150\n",
      " - 0s - loss: 0.7584 - acc: 1.0000\n",
      "Epoch 25/150\n",
      " - 0s - loss: 0.7498 - acc: 1.0000\n",
      "Epoch 26/150\n",
      " - 0s - loss: 0.7422 - acc: 1.0000\n",
      "Epoch 27/150\n",
      " - 0s - loss: 0.7342 - acc: 1.0000\n",
      "Epoch 28/150\n",
      " - 0s - loss: 0.7279 - acc: 1.0000\n",
      "Epoch 29/150\n",
      " - 0s - loss: 0.7221 - acc: 1.0000\n",
      "Epoch 30/150\n",
      " - 0s - loss: 0.7167 - acc: 1.0000\n",
      "Epoch 31/150\n",
      " - 0s - loss: 0.7117 - acc: 1.0000\n",
      "Epoch 32/150\n",
      " - 0s - loss: 0.7072 - acc: 1.0000\n",
      "Epoch 33/150\n",
      " - 0s - loss: 0.7031 - acc: 1.0000\n",
      "Epoch 34/150\n",
      " - 0s - loss: 0.6994 - acc: 1.0000\n",
      "Epoch 35/150\n",
      " - 0s - loss: 0.6958 - acc: 1.0000\n",
      "Epoch 36/150\n",
      " - 0s - loss: 0.6929 - acc: 1.0000\n",
      "Epoch 37/150\n",
      " - 0s - loss: 0.6899 - acc: 1.0000\n",
      "Epoch 38/150\n",
      " - 0s - loss: 0.6872 - acc: 1.0000\n",
      "Epoch 39/150\n",
      " - 0s - loss: 0.6846 - acc: 1.0000\n",
      "Epoch 40/150\n",
      " - 0s - loss: 0.6823 - acc: 1.0000\n",
      "Epoch 41/150\n",
      " - 0s - loss: 0.6802 - acc: 1.0000\n",
      "Epoch 42/150\n",
      " - 0s - loss: 0.6782 - acc: 1.0000\n",
      "Epoch 43/150\n",
      " - 0s - loss: 0.6763 - acc: 1.0000\n",
      "Epoch 44/150\n",
      " - 0s - loss: 0.6747 - acc: 1.0000\n",
      "Epoch 45/150\n",
      " - 0s - loss: 0.6730 - acc: 1.0000\n",
      "Epoch 46/150\n",
      " - 0s - loss: 0.6715 - acc: 1.0000\n",
      "Epoch 47/150\n",
      " - 0s - loss: 0.6700 - acc: 1.0000\n",
      "Epoch 48/150\n",
      " - 0s - loss: 0.6687 - acc: 1.0000\n",
      "Epoch 49/150\n",
      " - 0s - loss: 0.6677 - acc: 1.0000\n",
      "Epoch 50/150\n",
      " - 0s - loss: 0.6663 - acc: 1.0000\n",
      "Epoch 51/150\n",
      " - 0s - loss: 0.6652 - acc: 1.0000\n",
      "Epoch 52/150\n",
      " - 0s - loss: 0.6642 - acc: 1.0000\n",
      "Epoch 53/150\n",
      " - 0s - loss: 0.6632 - acc: 1.0000\n",
      "Epoch 54/150\n",
      " - 0s - loss: 0.6623 - acc: 1.0000\n",
      "Epoch 55/150\n",
      " - 0s - loss: 0.6616 - acc: 1.0000\n",
      "Epoch 56/150\n",
      " - 0s - loss: 0.6605 - acc: 1.0000\n",
      "Epoch 57/150\n",
      " - 0s - loss: 0.6597 - acc: 1.0000\n",
      "Epoch 58/150\n",
      " - 0s - loss: 0.6591 - acc: 1.0000\n",
      "Epoch 59/150\n",
      " - 0s - loss: 0.6583 - acc: 1.0000\n",
      "Epoch 60/150\n",
      " - 0s - loss: 0.6576 - acc: 1.0000\n",
      "Epoch 61/150\n",
      " - 0s - loss: 0.6570 - acc: 1.0000\n",
      "Epoch 62/150\n",
      " - 0s - loss: 0.6563 - acc: 1.0000\n",
      "Epoch 63/150\n",
      " - 0s - loss: 0.6558 - acc: 1.0000\n",
      "Epoch 64/150\n",
      " - 0s - loss: 0.6552 - acc: 1.0000\n",
      "Epoch 65/150\n",
      " - 0s - loss: 0.6546 - acc: 1.0000\n",
      "Epoch 66/150\n",
      " - 0s - loss: 0.6542 - acc: 1.0000\n",
      "Epoch 67/150\n",
      " - 0s - loss: 0.6536 - acc: 1.0000\n",
      "Epoch 68/150\n",
      " - 0s - loss: 0.6533 - acc: 1.0000\n",
      "Epoch 69/150\n",
      " - 0s - loss: 0.6528 - acc: 1.0000\n",
      "Epoch 70/150\n",
      " - 0s - loss: 0.6524 - acc: 1.0000\n",
      "Epoch 71/150\n",
      " - 0s - loss: 0.6519 - acc: 1.0000\n",
      "Epoch 72/150\n",
      " - 0s - loss: 0.6515 - acc: 1.0000\n",
      "Epoch 73/150\n",
      " - 0s - loss: 0.6512 - acc: 1.0000\n",
      "Epoch 74/150\n",
      " - 0s - loss: 0.6508 - acc: 1.0000\n",
      "Epoch 75/150\n",
      " - 0s - loss: 0.6506 - acc: 1.0000\n",
      "Epoch 76/150\n",
      " - 0s - loss: 0.6501 - acc: 1.0000\n",
      "Epoch 77/150\n",
      " - 0s - loss: 0.6497 - acc: 1.0000\n",
      "Epoch 78/150\n",
      " - 0s - loss: 0.6494 - acc: 1.0000\n",
      "Epoch 79/150\n",
      " - 0s - loss: 0.6491 - acc: 1.0000\n",
      "Epoch 80/150\n",
      " - 0s - loss: 0.6489 - acc: 1.0000\n",
      "Epoch 81/150\n",
      " - 0s - loss: 0.6486 - acc: 1.0000\n",
      "Epoch 82/150\n",
      " - 0s - loss: 0.6483 - acc: 1.0000\n",
      "Epoch 83/150\n",
      " - 0s - loss: 0.6481 - acc: 1.0000\n",
      "Epoch 84/150\n",
      " - 0s - loss: 0.6478 - acc: 1.0000\n",
      "Epoch 85/150\n",
      " - 0s - loss: 0.6477 - acc: 1.0000\n",
      "Epoch 86/150\n",
      " - 0s - loss: 0.6474 - acc: 1.0000\n",
      "Epoch 87/150\n",
      " - 0s - loss: 0.6471 - acc: 1.0000\n",
      "Epoch 88/150\n",
      " - 0s - loss: 0.6469 - acc: 1.0000\n",
      "Epoch 89/150\n",
      " - 0s - loss: 0.6467 - acc: 1.0000\n",
      "Epoch 90/150\n",
      " - 0s - loss: 0.6464 - acc: 1.0000\n",
      "Epoch 91/150\n",
      " - 0s - loss: 0.6464 - acc: 1.0000\n",
      "Epoch 92/150\n",
      " - 0s - loss: 0.6460 - acc: 1.0000\n",
      "Epoch 93/150\n",
      " - 0s - loss: 0.6459 - acc: 1.0000\n",
      "Epoch 94/150\n",
      " - 0s - loss: 0.6457 - acc: 1.0000\n",
      "Epoch 95/150\n",
      " - 0s - loss: 0.6455 - acc: 1.0000\n",
      "Epoch 96/150\n",
      " - 0s - loss: 0.6453 - acc: 1.0000\n",
      "Epoch 97/150\n",
      " - 0s - loss: 0.6451 - acc: 1.0000\n",
      "Epoch 98/150\n",
      " - 0s - loss: 0.6451 - acc: 1.0000\n",
      "Epoch 99/150\n",
      " - 0s - loss: 0.6448 - acc: 1.0000\n",
      "Epoch 100/150\n",
      " - 0s - loss: 0.6446 - acc: 1.0000\n",
      "Epoch 101/150\n",
      " - 0s - loss: 0.6446 - acc: 1.0000\n",
      "Epoch 102/150\n",
      " - 0s - loss: 0.6444 - acc: 1.0000\n",
      "Epoch 103/150\n",
      " - 0s - loss: 0.6443 - acc: 1.0000\n",
      "Epoch 104/150\n",
      " - 0s - loss: 0.6443 - acc: 1.0000\n",
      "Epoch 105/150\n",
      " - 0s - loss: 0.6441 - acc: 1.0000\n",
      "Epoch 106/150\n",
      " - 0s - loss: 0.6439 - acc: 1.0000\n",
      "Epoch 107/150\n",
      " - 0s - loss: 0.6439 - acc: 1.0000\n",
      "Epoch 108/150\n",
      " - 0s - loss: 0.6435 - acc: 1.0000\n",
      "Epoch 109/150\n",
      " - 0s - loss: 0.6435 - acc: 1.0000\n",
      "Epoch 110/150\n",
      " - 0s - loss: 0.6434 - acc: 1.0000\n",
      "Epoch 111/150\n",
      " - 0s - loss: 0.6432 - acc: 1.0000\n",
      "Epoch 112/150\n",
      " - 0s - loss: 0.6434 - acc: 1.0000\n",
      "Epoch 113/150\n",
      " - 0s - loss: 0.6430 - acc: 1.0000\n",
      "Epoch 114/150\n",
      " - 0s - loss: 0.6430 - acc: 1.0000\n",
      "Epoch 115/150\n",
      " - 0s - loss: 0.6433 - acc: 1.0000\n",
      "Epoch 116/150\n",
      " - 0s - loss: 0.6427 - acc: 1.0000\n",
      "Epoch 117/150\n",
      " - 0s - loss: 0.6427 - acc: 1.0000\n",
      "Epoch 118/150\n",
      " - 0s - loss: 0.6429 - acc: 1.0000\n",
      "Epoch 119/150\n",
      " - 0s - loss: 0.6426 - acc: 1.0000\n",
      "Epoch 120/150\n",
      " - 0s - loss: 0.6423 - acc: 1.0000\n",
      "Epoch 121/150\n",
      " - 0s - loss: 0.6422 - acc: 1.0000\n",
      "Epoch 122/150\n",
      " - 0s - loss: 0.6421 - acc: 1.0000\n",
      "Epoch 123/150\n",
      " - 0s - loss: 0.6421 - acc: 1.0000\n",
      "Epoch 124/150\n",
      " - 0s - loss: 0.6421 - acc: 1.0000\n",
      "Epoch 125/150\n",
      " - 0s - loss: 0.6419 - acc: 1.0000\n",
      "Epoch 126/150\n",
      " - 0s - loss: 0.6418 - acc: 1.0000\n",
      "Epoch 127/150\n",
      " - 0s - loss: 0.6418 - acc: 1.0000\n",
      "Epoch 128/150\n",
      " - 0s - loss: 0.6417 - acc: 1.0000\n",
      "Epoch 129/150\n",
      " - 0s - loss: 0.6416 - acc: 1.0000\n",
      "Epoch 130/150\n",
      " - 0s - loss: 0.6416 - acc: 1.0000\n",
      "Epoch 131/150\n",
      " - 0s - loss: 0.6414 - acc: 1.0000\n",
      "Epoch 132/150\n",
      " - 0s - loss: 0.6414 - acc: 1.0000\n",
      "Epoch 133/150\n",
      " - 0s - loss: 0.6413 - acc: 1.0000\n",
      "Epoch 134/150\n",
      " - 0s - loss: 0.6413 - acc: 1.0000\n",
      "Epoch 135/150\n",
      " - 0s - loss: 0.6412 - acc: 1.0000\n",
      "Epoch 136/150\n",
      " - 0s - loss: 0.6411 - acc: 1.0000\n",
      "Epoch 137/150\n",
      " - 0s - loss: 0.6411 - acc: 1.0000\n",
      "Epoch 138/150\n",
      " - 0s - loss: 0.6412 - acc: 1.0000\n",
      "Epoch 139/150\n",
      " - 0s - loss: 0.6410 - acc: 1.0000\n",
      "Epoch 140/150\n",
      " - 0s - loss: 0.6409 - acc: 1.0000\n",
      "Epoch 141/150\n",
      " - 0s - loss: 0.6408 - acc: 1.0000\n",
      "Epoch 142/150\n",
      " - 0s - loss: 0.6408 - acc: 1.0000\n",
      "Epoch 143/150\n",
      " - 0s - loss: 0.6408 - acc: 1.0000\n",
      "Epoch 144/150\n",
      " - 0s - loss: 0.6409 - acc: 1.0000\n",
      "Epoch 145/150\n",
      " - 0s - loss: 0.6408 - acc: 1.0000\n",
      "Epoch 146/150\n",
      " - 0s - loss: 0.6406 - acc: 1.0000\n",
      "Epoch 147/150\n",
      " - 0s - loss: 0.6405 - acc: 1.0000\n",
      "Epoch 148/150\n",
      " - 0s - loss: 0.6404 - acc: 1.0000\n",
      "Epoch 149/150\n",
      " - 0s - loss: 0.6405 - acc: 1.0000\n",
      "Epoch 150/150\n",
      " - 0s - loss: 0.6403 - acc: 1.0000\n",
      "Predictions\n",
      "[[ 0.00951687  0.88587338]\n",
      " [ 0.00971489  0.88433814]\n",
      " [ 0.00958713  0.88532382]\n",
      " [ 0.00977405  0.88389021]\n",
      " [ 0.00950195  0.88599241]\n",
      " [ 0.00957636  0.88539886]\n",
      " [ 0.00962779  0.88500708]\n",
      " [ 0.00958212  0.88535941]\n",
      " [ 0.00986819  0.88318801]\n",
      " [ 0.00964536  0.88487065]\n",
      " [ 0.00949155  0.88607419]\n",
      " [ 0.00964865  0.88484347]\n",
      " [ 0.00964377  0.88488489]\n",
      " [ 0.00954985  0.8856191 ]\n",
      " [ 0.00942837  0.88659108]\n",
      " [ 0.00944437  0.88645697]\n",
      " [ 0.00947323  0.88622195]\n",
      " [ 0.0095553   0.8855691 ]\n",
      " [ 0.00954064  0.88568008]\n",
      " [ 0.00951387  0.88589603]\n",
      " [ 0.00964562  0.88486141]\n",
      " [ 0.00958119  0.88536429]\n",
      " [ 0.00945126  0.8864032 ]\n",
      " [ 0.01023402  0.88046902]\n",
      " [ 0.0099046   0.88289845]\n",
      " [ 0.00988514  0.88304901]\n",
      " [ 0.00981615  0.88356233]\n",
      " [ 0.00954044  0.88568574]\n",
      " [ 0.00953417  0.88573599]\n",
      " [ 0.00977651  0.88386863]\n",
      " [ 0.00983628  0.88341725]\n",
      " [ 0.00967869  0.88460672]\n",
      " [ 0.00944002  0.8864941 ]\n",
      " [ 0.00943317  0.88655078]\n",
      " [ 0.00964536  0.88487065]\n",
      " [ 0.00953247  0.88575161]\n",
      " [ 0.0094808   0.88616127]\n",
      " [ 0.00964536  0.88487065]\n",
      " [ 0.00970599  0.88441169]\n",
      " [ 0.00957497  0.88541484]\n",
      " [ 0.00952904  0.88577735]\n",
      " [ 0.01093785  0.87556738]\n",
      " [ 0.00961119  0.88513875]\n",
      " [ 0.01003186  0.88194925]\n",
      " [ 0.00978194  0.88381368]\n",
      " [ 0.0098434   0.88336641]\n",
      " [ 0.00950729  0.88594854]\n",
      " [ 0.00964543  0.8848722 ]\n",
      " [ 0.00949508  0.88604611]\n",
      " [ 0.00957384  0.88542503]\n",
      " [ 0.5499537   0.27537164]\n",
      " [ 0.54995835  0.27536917]\n",
      " [ 0.55001366  0.27533701]\n",
      " [ 0.54981899  0.27544895]\n",
      " [ 0.54998636  0.27535293]\n",
      " [ 0.54991311  0.27539518]\n",
      " [ 0.54998696  0.27535263]\n",
      " [ 0.5489971   0.27590749]\n",
      " [ 0.54996246  0.27536681]\n",
      " [ 0.54975742  0.27548385]\n",
      " [ 0.54940051  0.27568415]\n",
      " [ 0.5498963   0.27540484]\n",
      " [ 0.54977298  0.27547505]\n",
      " [ 0.54997039  0.27536222]\n",
      " [ 0.5493421   0.27571499]\n",
      " [ 0.5498926   0.27540663]\n",
      " [ 0.54993445  0.27538294]\n",
      " [ 0.5496676   0.27553412]\n",
      " [ 0.54998529  0.27535358]\n",
      " [ 0.54970068  0.27551591]\n",
      " [ 0.55000693  0.27534094]\n",
      " [ 0.54979092  0.27546465]\n",
      " [ 0.55001396  0.27533686]\n",
      " [ 0.54994649  0.27537602]\n",
      " [ 0.54988581  0.27541074]\n",
      " [ 0.54993099  0.27538487]\n",
      " [ 0.55000252  0.27534351]\n",
      " [ 0.55003071  0.27532703]\n",
      " [ 0.54995507  0.27537107]\n",
      " [ 0.54870087  0.27606612]\n",
      " [ 0.54965711  0.27554047]\n",
      " [ 0.54954588  0.27560291]\n",
      " [ 0.54971772  0.27550614]\n",
      " [ 0.55002433  0.27533078]\n",
      " [ 0.54992533  0.27538821]\n",
      " [ 0.54994982  0.27537408]\n",
      " [ 0.5499931   0.27534905]\n",
      " [ 0.5499475   0.27537543]\n",
      " [ 0.54979706  0.27546141]\n",
      " [ 0.54980206  0.27545857]\n",
      " [ 0.54987162  0.27541897]\n",
      " [ 0.54995412  0.27537158]\n",
      " [ 0.54978627  0.27546751]\n",
      " [ 0.54914731  0.27582487]\n",
      " [ 0.54984909  0.27543178]\n",
      " [ 0.54977959  0.27547115]\n",
      " [ 0.54984152  0.2754361 ]\n",
      " [ 0.54989654  0.27540469]\n",
      " [ 0.54791313  0.27649605]\n",
      " [ 0.54982239  0.27544701]\n",
      " [ 0.55006933  0.27530396]\n",
      " [ 0.5500375   0.27532303]\n",
      " [ 0.55006737  0.27530512]\n",
      " [ 0.5500536   0.27531347]\n",
      " [ 0.55006552  0.27530628]\n",
      " [ 0.55007315  0.27530164]\n",
      " [ 0.54995739  0.2753697 ]\n",
      " [ 0.55006897  0.2753042 ]\n",
      " [ 0.55006236  0.27530819]\n",
      " [ 0.55007124  0.27530277]\n",
      " [ 0.55004382  0.27531928]\n",
      " [ 0.55005068  0.27531523]\n",
      " [ 0.55006069  0.27530918]\n",
      " [ 0.55003905  0.27532211]\n",
      " [ 0.55005425  0.27531308]\n",
      " [ 0.55005759  0.27531105]\n",
      " [ 0.55005169  0.2753146 ]\n",
      " [ 0.55007315  0.27530164]\n",
      " [ 0.55007505  0.27530038]\n",
      " [ 0.55002064  0.27533296]\n",
      " [ 0.55006623  0.27530581]\n",
      " [ 0.55002892  0.27532807]\n",
      " [ 0.55007344  0.27530143]\n",
      " [ 0.55002964  0.27532765]\n",
      " [ 0.55006212  0.27530834]\n",
      " [ 0.55006438  0.27530694]\n",
      " [ 0.55002081  0.27533287]\n",
      " [ 0.55002165  0.27533236]\n",
      " [ 0.55006146  0.27530873]\n",
      " [ 0.55005842  0.27531055]\n",
      " [ 0.55006862  0.27530438]\n",
      " [ 0.55007064  0.2753031 ]\n",
      " [ 0.55006319  0.27530769]\n",
      " [ 0.55002135  0.27533254]\n",
      " [ 0.5500409   0.27532101]\n",
      " [ 0.55007184  0.27530238]\n",
      " [ 0.55006331  0.2753076 ]\n",
      " [ 0.55005002  0.27531561]\n",
      " [ 0.55001324  0.27533731]\n",
      " [ 0.55005878  0.27531034]\n",
      " [ 0.55006599  0.27530602]\n",
      " [ 0.55005699  0.27531141]\n",
      " [ 0.5500375   0.27532303]\n",
      " [ 0.55006808  0.2753047 ]\n",
      " [ 0.5500676   0.27530494]\n",
      " [ 0.55005848  0.27531052]\n",
      " [ 0.55004156  0.27532059]\n",
      " [ 0.55004913  0.27531612]\n",
      " [ 0.55005735  0.27531123]\n",
      " [ 0.5500297   0.27532762]]\n",
      "Rounded values for the prediciton:\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy\n",
    "\n",
    "def converttonumbers(x):\n",
    "    if x == \"Iris-setosa\":\n",
    "        return 1\n",
    "    elif x == \"Iris-versicolor\":\n",
    "        return 2\n",
    "    elif x == \"Iris-virginica\":\n",
    "        return 3\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "dataset = numpy.loadtxt(\"iris_text.data\", delimiter=\",\")\n",
    "\n",
    "X = dataset[:,0:5]\n",
    "Y = dataset[:,4:6]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim = 5, kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dense(8, kernel_initializer='uniform', activation='sigmoid'))\n",
    "model.add(Dense(2, kernel_initializer='uniform', activation='sigmoid'))\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "\n",
    "model.fit(X, Y, epochs = 150, batch_size = 10, verbose = 2, )\n",
    "\n",
    "predictions = model.predict(X)\n",
    "\n",
    "# round predictions\n",
    "rounded1 = [round(x[0]) for x in predictions]\n",
    "rounded2 = [round(x[1]) for x in predictions]\n",
    "\n",
    "print(\"Predictions\")\n",
    "print(predictions)\n",
    "\n",
    "print(\"Rounded values for the prediciton:\")\n",
    "print(rounded1)\n",
    "print(rounded2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
